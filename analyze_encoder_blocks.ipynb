{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Block Comparison: JeongWonNet vs CMUNeXt\n",
    "\n",
    "인코더 블록 구조, 파라미터, FLOPs, Latency 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:54.943186Z",
     "iopub.status.busy": "2026-02-12T04:48:54.943088Z",
     "iopub.status.idle": "2026-02-12T04:48:56.340760Z",
     "shell.execute_reply": "2026-02-12T04:48:56.340243Z",
     "shell.execute_reply.started": "2026-02-12T04:48:54.943179Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanghyuck/anaconda3/envs/Skin_Lesion_Seg/lib/python3.8/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from thop import profile\n",
    "\n",
    "from models import JeongWonNet, CMUNeXt\n",
    "from models.JeongWonNet import PRCM\n",
    "from models.CMUNeXt import CMUNeXtBlock, conv_block\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Block Structure Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:56.341377Z",
     "iopub.status.busy": "2026-02-12T04:48:56.341200Z",
     "iopub.status.idle": "2026-02-12T04:48:56.345243Z",
     "shell.execute_reply": "2026-02-12T04:48:56.345011Z",
     "shell.execute_reply.started": "2026-02-12T04:48:56.341364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "JeongWonNet Encoder Block Structure\n",
      "======================================================================\n",
      "\n",
      "Input (in_ch)\n",
      "    │\n",
      "    ├─► [1x1 Conv] Pointwise (in_ch → out_ch)  ← 채널 조정\n",
      "    │\n",
      "    ├─► [3x3 DWConv] Depthwise (out_ch → out_ch, groups=out_ch)\n",
      "    │\n",
      "    ├─► [GroupNorm + GELU]\n",
      "    │\n",
      "    └─► [PRCM] Channel Mixer (out_ch → out_ch)\n",
      "    │\n",
      "Output (out_ch)\n",
      "\n",
      "Key: Depthwise Separable Conv + Channel Attention\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CMUNeXt Encoder Block Structure (CMUNeXtBlock)\n",
      "======================================================================\n",
      "\n",
      "Input (ch_in)\n",
      "    │\n",
      "    ├─► [Residual Block] x depth times:\n",
      "    │       │\n",
      "    │       ├─► Residual(\n",
      "    │       │       [3x3 DWConv] (ch_in → ch_in, groups=ch_in)\n",
      "    │       │       [GELU + BatchNorm]\n",
      "    │       │   )\n",
      "    │       │\n",
      "    │       ├─► [1x1 Conv] Expansion (ch_in → ch_in * 4)  ← 4배 확장!\n",
      "    │       ├─► [GELU + BatchNorm]\n",
      "    │       │\n",
      "    │       ├─► [1x1 Conv] Reduction (ch_in * 4 → ch_in)  ← 다시 축소\n",
      "    │       └─► [GELU + BatchNorm]\n",
      "    │\n",
      "    └─► [conv_block] Standard 3x3 Conv (ch_in → ch_out)\n",
      "    │\n",
      "Output (ch_out)\n",
      "\n",
      "Key: 4x Channel Expansion + Standard 3x3 Conv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"JeongWonNet Encoder Block Structure\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Input (in_ch)\n",
    "    │\n",
    "    ├─► [1x1 Conv] Pointwise (in_ch → out_ch)  ← 채널 조정\n",
    "    │\n",
    "    ├─► [3x3 DWConv] Depthwise (out_ch → out_ch, groups=out_ch)\n",
    "    │\n",
    "    ├─► [GroupNorm + GELU]\n",
    "    │\n",
    "    └─► [PRCM] Channel Mixer (out_ch → out_ch)\n",
    "    │\n",
    "Output (out_ch)\n",
    "\n",
    "Key: Depthwise Separable Conv + Channel Attention\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CMUNeXt Encoder Block Structure (CMUNeXtBlock)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Input (ch_in)\n",
    "    │\n",
    "    ├─► [Residual Block] x depth times:\n",
    "    │       │\n",
    "    │       ├─► Residual(\n",
    "    │       │       [3x3 DWConv] (ch_in → ch_in, groups=ch_in)\n",
    "    │       │       [GELU + BatchNorm]\n",
    "    │       │   )\n",
    "    │       │\n",
    "    │       ├─► [1x1 Conv] Expansion (ch_in → ch_in * 4)  ← 4배 확장!\n",
    "    │       ├─► [GELU + BatchNorm]\n",
    "    │       │\n",
    "    │       ├─► [1x1 Conv] Reduction (ch_in * 4 → ch_in)  ← 다시 축소\n",
    "    │       └─► [GELU + BatchNorm]\n",
    "    │\n",
    "    └─► [conv_block] Standard 3x3 Conv (ch_in → ch_out)\n",
    "    │\n",
    "Output (ch_out)\n",
    "\n",
    "Key: 4x Channel Expansion + Standard 3x3 Conv\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Isolated Encoder Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:56.346223Z",
     "iopub.status.busy": "2026-02-12T04:48:56.346121Z",
     "iopub.status.idle": "2026-02-12T04:48:56.354945Z",
     "shell.execute_reply": "2026-02-12T04:48:56.354590Z",
     "shell.execute_reply.started": "2026-02-12T04:48:56.346213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Configurations:\n",
      "  JeongWonNet: 3 → [6, 12, 18, 24, 32, 48]\n",
      "  CMUNeXt:     3 → [8, 8, 16, 24, 32, 48]\n",
      "  CMUNeXt depths: [1, 1, 1, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "# JeongWonNet style encoder block\n",
    "def make_jwn_block(in_ch, out_ch):\n",
    "    \"\"\"JeongWonNet 스타일 인코더 블록 생성\"\"\"\n",
    "    layers = []\n",
    "    if in_ch != out_ch:\n",
    "        layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False))\n",
    "    layers.append(nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, groups=out_ch, bias=False))\n",
    "    num_groups = min(4, out_ch)\n",
    "    while out_ch % num_groups != 0:\n",
    "        num_groups -= 1\n",
    "    layers.append(nn.GroupNorm(num_groups, out_ch))\n",
    "    layers.append(nn.GELU())\n",
    "    layers.append(PRCM(out_ch, num_basis=2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Channel configurations\n",
    "jwn_channels = [3, 6, 12, 18, 24, 32, 48]  # input → c_list\n",
    "cmu_channels = [3, 8, 8, 16, 24, 32, 48]   # input → dims (stem: 3→8, enc1: 8→8)\n",
    "cmu_depths = [1, 1, 1, 3, 1]\n",
    "cmu_kernels = [3, 3, 7, 7, 7]\n",
    "\n",
    "print(\"Channel Configurations:\")\n",
    "print(f\"  JeongWonNet: {jwn_channels[0]} → {jwn_channels[1:]}\")\n",
    "print(f\"  CMUNeXt:     {cmu_channels[0]} → {cmu_channels[1:]}\")\n",
    "print(f\"  CMUNeXt depths: {cmu_depths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Count Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:56.355586Z",
     "iopub.status.busy": "2026-02-12T04:48:56.355319Z",
     "iopub.status.idle": "2026-02-12T04:48:56.367569Z",
     "shell.execute_reply": "2026-02-12T04:48:56.367298Z",
     "shell.execute_reply.started": "2026-02-12T04:48:56.355574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Parameter Count per Encoder Block\n",
      "======================================================================\n",
      "Stage      JWN (in→out)    JWN Params   CMU (in→out)    CMU Params   Ratio\n",
      "----------------------------------------------------------------------\n",
      "Enc1     3→6             108          3→8 (stem)      240          2.2x\n",
      "Enc2     6→12            252          8→8 (d=1)       1.33K        5.3x\n",
      "Enc3     12→18           486          8→16 (d=1)      1.93K        4.0x\n",
      "Enc4     18→24           792          16→24 (d=1)     6.65K        8.4x\n",
      "Enc5     24→32           1.25K        24→32 (d=3)     25.66K       20.6x\n",
      "Enc6     32→48           2.26K        32→48 (d=1)     24.30K       10.8x\n",
      "----------------------------------------------------------------------\n",
      "Total                      5.14K                        60.10K       11.7x\n"
     ]
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def format_num(n):\n",
    "    if n >= 1e6: return f\"{n/1e6:.2f}M\"\n",
    "    if n >= 1e3: return f\"{n/1e3:.2f}K\"\n",
    "    return str(n)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Parameter Count per Encoder Block\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Stage':<10} {'JWN (in→out)':<15} {'JWN Params':<12} {'CMU (in→out)':<15} {'CMU Params':<12} {'Ratio'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# JeongWonNet blocks\n",
    "jwn_blocks = []\n",
    "for i in range(6):\n",
    "    in_ch = jwn_channels[i]\n",
    "    out_ch = jwn_channels[i+1]\n",
    "    block = make_jwn_block(in_ch, out_ch)\n",
    "    jwn_blocks.append((f\"{in_ch}→{out_ch}\", count_params(block)))\n",
    "\n",
    "# CMUNeXt blocks (stem + encoders)\n",
    "cmu_blocks = []\n",
    "# Stem: conv_block(3, 8)\n",
    "stem = conv_block(3, 8)\n",
    "cmu_blocks.append((\"3→8 (stem)\", count_params(stem)))\n",
    "\n",
    "# Encoder blocks\n",
    "for i in range(5):\n",
    "    in_ch = cmu_channels[i+1]\n",
    "    out_ch = cmu_channels[i+2]\n",
    "    block = CMUNeXtBlock(in_ch, out_ch, depth=cmu_depths[i], k=cmu_kernels[i])\n",
    "    cmu_blocks.append((f\"{in_ch}→{out_ch} (d={cmu_depths[i]})\", count_params(block)))\n",
    "\n",
    "# Print comparison\n",
    "for i in range(6):\n",
    "    jwn_ch, jwn_p = jwn_blocks[i]\n",
    "    cmu_ch, cmu_p = cmu_blocks[i]\n",
    "    ratio = cmu_p / jwn_p if jwn_p > 0 else 0\n",
    "    print(f\"Enc{i+1:<5} {jwn_ch:<15} {format_num(jwn_p):<12} {cmu_ch:<15} {format_num(cmu_p):<12} {ratio:.1f}x\")\n",
    "    results.append({\n",
    "        'Stage': f'Enc{i+1}',\n",
    "        'JWN_channels': jwn_ch,\n",
    "        'JWN_params': jwn_p,\n",
    "        'CMU_channels': cmu_ch,\n",
    "        'CMU_params': cmu_p,\n",
    "        'Param_ratio': ratio\n",
    "    })\n",
    "\n",
    "print(\"-\"*70)\n",
    "jwn_total = sum(b[1] for b in jwn_blocks)\n",
    "cmu_total = sum(b[1] for b in cmu_blocks)\n",
    "print(f\"{'Total':<10} {'':<15} {format_num(jwn_total):<12} {'':<15} {format_num(cmu_total):<12} {cmu_total/jwn_total:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FLOPs Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:56.368141Z",
     "iopub.status.busy": "2026-02-12T04:48:56.367900Z",
     "iopub.status.idle": "2026-02-12T04:48:56.573760Z",
     "shell.execute_reply": "2026-02-12T04:48:56.573514Z",
     "shell.execute_reply.started": "2026-02-12T04:48:56.368129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FLOPs per Encoder Block (256x256 input)\n",
      "======================================================================\n",
      "Stage      Resolution   JWN FLOPs    CMU FLOPs    Ratio\n",
      "----------------------------------------------------------------------\n",
      "Enc1     256x256      4.72M        16.25M       3.4x\n",
      "Enc2     128x128      2.95M        22.68M       7.7x\n",
      "Enc3     64x64       1.55M        8.16M        5.3x\n",
      "Enc4     32x32       663.60K      6.93M        10.4x\n",
      "Enc5     16x16       270.40K      6.69M        24.7x\n",
      "Enc6     8x8        126.05K      1.57M        12.5x\n"
     ]
    }
   ],
   "source": [
    "def measure_flops(model, input_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        flops, _ = profile(model, inputs=(input_tensor,), verbose=False)\n",
    "    return flops\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FLOPs per Encoder Block (256x256 input)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Stage':<10} {'Resolution':<12} {'JWN FLOPs':<12} {'CMU FLOPs':<12} {'Ratio'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Resolution at each stage (after pooling)\n",
    "resolutions = [256, 128, 64, 32, 16, 8]\n",
    "\n",
    "for i in range(6):\n",
    "    res = resolutions[i]\n",
    "    \n",
    "    # JeongWonNet block\n",
    "    in_ch = jwn_channels[i]\n",
    "    out_ch = jwn_channels[i+1]\n",
    "    jwn_block = make_jwn_block(in_ch, out_ch).to(DEVICE)\n",
    "    jwn_input = torch.randn(1, in_ch, res, res).to(DEVICE)\n",
    "    jwn_flops = measure_flops(jwn_block, jwn_input)\n",
    "    \n",
    "    # CMUNeXt block\n",
    "    if i == 0:\n",
    "        cmu_block = conv_block(3, 8).to(DEVICE)\n",
    "        cmu_input = torch.randn(1, 3, res, res).to(DEVICE)\n",
    "    else:\n",
    "        in_ch_cmu = cmu_channels[i]\n",
    "        out_ch_cmu = cmu_channels[i+1]\n",
    "        cmu_block = CMUNeXtBlock(in_ch_cmu, out_ch_cmu, depth=cmu_depths[i-1], k=cmu_kernels[i-1]).to(DEVICE)\n",
    "        cmu_input = torch.randn(1, in_ch_cmu, res, res).to(DEVICE)\n",
    "    cmu_flops = measure_flops(cmu_block, cmu_input)\n",
    "    \n",
    "    ratio = cmu_flops / jwn_flops if jwn_flops > 0 else 0\n",
    "    print(f\"Enc{i+1:<5} {res}x{res:<8} {format_num(jwn_flops):<12} {format_num(cmu_flops):<12} {ratio:.1f}x\")\n",
    "    \n",
    "    results[i]['JWN_flops'] = jwn_flops\n",
    "    results[i]['CMU_flops'] = cmu_flops\n",
    "    results[i]['FLOPs_ratio'] = ratio\n",
    "    \n",
    "    del jwn_block, cmu_block\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Latency Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:56.574203Z",
     "iopub.status.busy": "2026-02-12T04:48:56.574083Z",
     "iopub.status.idle": "2026-02-12T04:48:56.823121Z",
     "shell.execute_reply": "2026-02-12T04:48:56.822635Z",
     "shell.execute_reply.started": "2026-02-12T04:48:56.574194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Latency per Encoder Block (256x256 input, GPU)\n",
      "======================================================================\n",
      "Stage      Resolution   JWN (ms)        CMU (ms)        Ratio\n",
      "----------------------------------------------------------------------\n",
      "Enc1     256x256      0.120±0.028   0.065±0.027   0.5x\n",
      "Enc2     128x128      0.070±0.003   0.108±0.018   1.6x\n",
      "Enc3     64x64       0.067±0.024   0.092±0.026   1.4x\n",
      "Enc4     32x32       0.057±0.019   0.088±0.004   1.5x\n",
      "Enc5     16x16       0.058±0.024   0.205±0.035   3.6x\n",
      "Enc6     8x8        0.058±0.019   0.088±0.004   1.5x\n"
     ]
    }
   ],
   "source": [
    "NUM_WARMUP = 50\n",
    "NUM_ITER = 100\n",
    "\n",
    "def measure_latency(model, input_tensor):\n",
    "    model.eval()\n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(NUM_WARMUP):\n",
    "            _ = model(input_tensor)\n",
    "    if DEVICE.type == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    # Measure\n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(NUM_ITER):\n",
    "            if DEVICE.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            start = time.perf_counter()\n",
    "            _ = model(input_tensor)\n",
    "            if DEVICE.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            times.append((time.perf_counter() - start) * 1000)\n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Latency per Encoder Block (256x256 input, GPU)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Stage':<10} {'Resolution':<12} {'JWN (ms)':<15} {'CMU (ms)':<15} {'Ratio'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i in range(6):\n",
    "    res = resolutions[i]\n",
    "    \n",
    "    # JeongWonNet block\n",
    "    in_ch = jwn_channels[i]\n",
    "    out_ch = jwn_channels[i+1]\n",
    "    jwn_block = make_jwn_block(in_ch, out_ch).to(DEVICE)\n",
    "    jwn_input = torch.randn(1, in_ch, res, res).to(DEVICE)\n",
    "    jwn_mean, jwn_std = measure_latency(jwn_block, jwn_input)\n",
    "    \n",
    "    # CMUNeXt block\n",
    "    if i == 0:\n",
    "        cmu_block = conv_block(3, 8).to(DEVICE)\n",
    "        cmu_input = torch.randn(1, 3, res, res).to(DEVICE)\n",
    "    else:\n",
    "        in_ch_cmu = cmu_channels[i]\n",
    "        out_ch_cmu = cmu_channels[i+1]\n",
    "        cmu_block = CMUNeXtBlock(in_ch_cmu, out_ch_cmu, depth=cmu_depths[i-1], k=cmu_kernels[i-1]).to(DEVICE)\n",
    "        cmu_input = torch.randn(1, in_ch_cmu, res, res).to(DEVICE)\n",
    "    cmu_mean, cmu_std = measure_latency(cmu_block, cmu_input)\n",
    "    \n",
    "    ratio = cmu_mean / jwn_mean if jwn_mean > 0 else 0\n",
    "    print(f\"Enc{i+1:<5} {res}x{res:<8} {jwn_mean:.3f}±{jwn_std:.3f}   {cmu_mean:.3f}±{cmu_std:.3f}   {ratio:.1f}x\")\n",
    "    \n",
    "    results[i]['JWN_latency'] = jwn_mean\n",
    "    results[i]['CMU_latency'] = cmu_mean\n",
    "    results[i]['Latency_ratio'] = ratio\n",
    "    \n",
    "    del jwn_block, cmu_block\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Why the Difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:56.823610Z",
     "iopub.status.busy": "2026-02-12T04:48:56.823523Z",
     "iopub.status.idle": "2026-02-12T04:48:56.826459Z",
     "shell.execute_reply": "2026-02-12T04:48:56.826265Z",
     "shell.execute_reply.started": "2026-02-12T04:48:56.823601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Root Cause Analysis: Why CMUNeXt Encoder is Slower\n",
      "======================================================================\n",
      "\n",
      "[Example: 64x64 resolution, ~24 channels]\n",
      "\n",
      "JeongWonNet (18→24):\n",
      "  1x1 Conv:    18 × 24 × 1 × 1         = 432 params\n",
      "  3x3 DWConv:  24 × 1 × 3 × 3          = 216 params\n",
      "  PRCM:        2 × 24 + 2 × 24         = 96 params\n",
      "  GroupNorm:   24 × 2                  = 48 params\n",
      "  ─────────────────────────────────────────────\n",
      "  Total:                               ≈ 792 params\n",
      "\n",
      "CMUNeXt (24→32, depth=1, k=7):\n",
      "  [Residual DWConv] 24 × 7 × 7         = 1,176 params\n",
      "  [1x1 Expansion]   24 × 96            = 2,304 params  ← 4x expansion!\n",
      "  [1x1 Reduction]   96 × 24            = 2,304 params\n",
      "  [conv_block 3x3]  24 × 32 × 3 × 3    = 6,912 params  ← Standard conv!\n",
      "  [BatchNorms]      ...                ≈ 400 params\n",
      "  ─────────────────────────────────────────────\n",
      "  Total:                               ≈ 13,096 params\n",
      "\n",
      "======================================================================\n",
      "Key Differences:\n",
      "======================================================================\n",
      "\n",
      "1. [4x Channel Expansion]\n",
      "   - CMUNeXt: ch → ch*4 → ch (MLP-like bottleneck)\n",
      "   - JeongWonNet: No expansion, direct channel mapping\n",
      "\n",
      "2. [Standard 3x3 Conv in conv_block]\n",
      "   - CMUNeXt conv_block: in_ch × out_ch × 3 × 3 params\n",
      "   - JeongWonNet DWConv: out_ch × 3 × 3 params (groups=out_ch)\n",
      "   - Ratio: in_ch times more parameters!\n",
      "\n",
      "3. [Larger Kernel Size at Deep Layers]\n",
      "   - CMUNeXt uses 7x7 DWConv at enc3, enc4, enc5\n",
      "   - JeongWonNet uses 3x3 DWConv everywhere\n",
      "   - 7x7 = 49 vs 3x3 = 9 (5.4x more ops per pixel)\n",
      "\n",
      "4. [depth Parameter]\n",
      "   - CMUNeXt enc4 has depth=3 (block repeated 3 times)\n",
      "   - JeongWonNet: single pass through each block\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Root Cause Analysis: Why CMUNeXt Encoder is Slower\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Example: Compare at 64x64, ch=24\n",
    "print(\"\\n[Example: 64x64 resolution, ~24 channels]\\n\")\n",
    "\n",
    "# JeongWonNet: 18 → 24\n",
    "print(\"JeongWonNet (18→24):\")\n",
    "print(\"  1x1 Conv:    18 × 24 × 1 × 1         = 432 params\")\n",
    "print(\"  3x3 DWConv:  24 × 1 × 3 × 3          = 216 params\")\n",
    "print(\"  PRCM:        2 × 24 + 2 × 24         = 96 params\")\n",
    "print(\"  GroupNorm:   24 × 2                  = 48 params\")\n",
    "print(\"  ─────────────────────────────────────────────\")\n",
    "print(\"  Total:                               ≈ 792 params\")\n",
    "\n",
    "print(\"\\nCMUNeXt (24→32, depth=1, k=7):\")\n",
    "print(\"  [Residual DWConv] 24 × 7 × 7         = 1,176 params\")\n",
    "print(\"  [1x1 Expansion]   24 × 96            = 2,304 params  ← 4x expansion!\")\n",
    "print(\"  [1x1 Reduction]   96 × 24            = 2,304 params\")\n",
    "print(\"  [conv_block 3x3]  24 × 32 × 3 × 3    = 6,912 params  ← Standard conv!\")\n",
    "print(\"  [BatchNorms]      ...                ≈ 400 params\")\n",
    "print(\"  ─────────────────────────────────────────────\")\n",
    "print(\"  Total:                               ≈ 13,096 params\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Key Differences:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. [4x Channel Expansion]\n",
    "   - CMUNeXt: ch → ch*4 → ch (MLP-like bottleneck)\n",
    "   - JeongWonNet: No expansion, direct channel mapping\n",
    "\n",
    "2. [Standard 3x3 Conv in conv_block]\n",
    "   - CMUNeXt conv_block: in_ch × out_ch × 3 × 3 params\n",
    "   - JeongWonNet DWConv: out_ch × 3 × 3 params (groups=out_ch)\n",
    "   - Ratio: in_ch times more parameters!\n",
    "\n",
    "3. [Larger Kernel Size at Deep Layers]\n",
    "   - CMUNeXt uses 7x7 DWConv at enc3, enc4, enc5\n",
    "   - JeongWonNet uses 3x3 DWConv everywhere\n",
    "   - 7x7 = 49 vs 3x3 = 9 (5.4x more ops per pixel)\n",
    "\n",
    "4. [depth Parameter]\n",
    "   - CMUNeXt enc4 has depth=3 (block repeated 3 times)\n",
    "   - JeongWonNet: single pass through each block\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T04:48:56.826826Z",
     "iopub.status.busy": "2026-02-12T04:48:56.826672Z",
     "iopub.status.idle": "2026-02-12T04:48:56.838640Z",
     "shell.execute_reply": "2026-02-12T04:48:56.838416Z",
     "shell.execute_reply.started": "2026-02-12T04:48:56.826819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Summary Table\n",
      "======================================================================\n",
      "Stage JWN_channels  JWN_params CMU_channels  CMU_params  Param_ratio  JWN_flops  CMU_flops  FLOPs_ratio  JWN_latency  CMU_latency  Latency_ratio\n",
      " Enc1          3→6         108   3→8 (stem)         240     2.222222  4718604.0 16252928.0     3.444436     0.119967     0.065277       0.544130\n",
      " Enc2         6→12         252    8→8 (d=1)        1328     5.269841  2949144.0 22675456.0     7.688826     0.069971     0.108497       1.550609\n",
      " Enc3        12→18         486   8→16 (d=1)        1928     3.967078  1548324.0  8159232.0     5.269719     0.067416     0.092177       1.367279\n",
      " Enc4        18→24         792  16→24 (d=1)        6648     8.393939   663600.0  6930432.0    10.443689     0.056683     0.087713       1.547437\n",
      " Enc5        24→32        1248  24→32 (d=3)       25656    20.557692   270400.0  6686720.0    24.728994     0.057781     0.205492       3.556374\n",
      " Enc6        32→48        2256  32→48 (d=1)       24304    10.773050   126048.0  1570816.0    12.462046     0.058423     0.088096       1.507903\n"
     ]
    }
   ],
   "source": [
    "# Summary DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Summary Table\")\n",
    "print(\"=\"*70)\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Skin_Lesion_Seg (Python 3.8)",
   "language": "python",
   "name": "skin_lesion_seg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Complexity Analysis\n",
    "\n",
    "JeongWonNet vs CMUNeXt 복잡도 비교 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from thop import profile\n",
    "from models import JeongWonNet, CMUNeXt\n",
    "\n",
    "INPUT_SIZE = (1, 3, 256, 256)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 전체 비교 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_stats(model, name, input_size):\n",
    "    \"\"\"모델 통계 계산\"\"\"\n",
    "    dummy = torch.randn(input_size).to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    # FLOPs\n",
    "    flops, _ = profile(model, inputs=(dummy,), verbose=False)\n",
    "    \n",
    "    # Model size (FP32)\n",
    "    size_mb = total_params * 4 / (1024 ** 2)\n",
    "    \n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Total Params': total_params,\n",
    "        'Trainable Params': trainable_params,\n",
    "        'FLOPs': flops,\n",
    "        'Size (MB)': size_mb\n",
    "    }\n",
    "\n",
    "# 모델 생성\n",
    "model1 = JeongWonNet(num_classes=1)\n",
    "model2 = CMUNeXt(num_classes=1)\n",
    "\n",
    "stats1 = get_model_stats(model1, 'JeongWonNet', INPUT_SIZE)\n",
    "stats2 = get_model_stats(model2, 'CMUNeXt', INPUT_SIZE)\n",
    "\n",
    "# 비교 테이블\n",
    "df_summary = pd.DataFrame([stats1, stats2])\n",
    "df_summary['Params Ratio'] = df_summary['Total Params'] / df_summary['Total Params'].min()\n",
    "df_summary['FLOPs Ratio'] = df_summary['FLOPs'] / df_summary['FLOPs'].min()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Overall Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'Metric':<20} {'JeongWonNet':>15} {'CMUNeXt':>15} {'Ratio':>10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Parameters':<20} {stats1['Total Params']:>15,} {stats2['Total Params']:>15,} {stats2['Total Params']/stats1['Total Params']:>10.1f}x\")\n",
    "print(f\"{'FLOPs':<20} {stats1['FLOPs']:>15,.0f} {stats2['FLOPs']:>15,.0f} {stats2['FLOPs']/stats1['FLOPs']:>10.1f}x\")\n",
    "print(f\"{'Size (MB)':<20} {stats1['Size (MB)']:>15.3f} {stats2['Size (MB)']:>15.3f} {stats2['Size (MB)']/stats1['Size (MB)']:>10.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 레이어별 파라미터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_layers(model, name):\n",
    "    \"\"\"레이어별 파라미터 분석\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name} - Layer Analysis\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    layer_stats = []\n",
    "    total = 0\n",
    "    \n",
    "    for name_layer, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear, nn.BatchNorm2d, nn.GroupNorm, nn.LayerNorm)):\n",
    "            params = sum(p.numel() for p in module.parameters())\n",
    "            if params > 0:\n",
    "                layer_stats.append({\n",
    "                    'Layer': name_layer,\n",
    "                    'Type': module.__class__.__name__,\n",
    "                    'Params': params\n",
    "                })\n",
    "                total += params\n",
    "    \n",
    "    df = pd.DataFrame(layer_stats)\n",
    "    df['Percentage'] = df['Params'] / total * 100\n",
    "    \n",
    "    # 타입별 집계\n",
    "    type_summary = df.groupby('Type')['Params'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    print(f\"\\n[By Layer Type]\")\n",
    "    print(f\"{'Type':<20} {'Params':>12} {'Percentage':>10}\")\n",
    "    print(\"-\"*45)\n",
    "    for t, p in type_summary.items():\n",
    "        print(f\"{t:<20} {p:>12,} {p/total*100:>9.1f}%\")\n",
    "    print(\"-\"*45)\n",
    "    print(f\"{'Total':<20} {total:>12,}\")\n",
    "    \n",
    "    return df, type_summary\n",
    "\n",
    "df1, type1 = analyze_layers(model1, 'JeongWonNet')\n",
    "df2, type2 = analyze_layers(model2, 'CMUNeXt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conv2d 레이어 상세 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_conv_layers(model, name):\n",
    "    \"\"\"Conv2d 레이어 상세 분석\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name} - Conv2d Analysis\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    conv_stats = []\n",
    "    \n",
    "    for name_layer, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            params = sum(p.numel() for p in module.parameters())\n",
    "            is_depthwise = module.groups == module.in_channels and module.groups > 1\n",
    "            is_pointwise = module.kernel_size == (1, 1)\n",
    "            \n",
    "            conv_type = 'Depthwise' if is_depthwise else ('Pointwise' if is_pointwise else 'Standard')\n",
    "            \n",
    "            conv_stats.append({\n",
    "                'Layer': name_layer.split('.')[-1] if '.' in name_layer else name_layer,\n",
    "                'Type': conv_type,\n",
    "                'In': module.in_channels,\n",
    "                'Out': module.out_channels,\n",
    "                'Kernel': module.kernel_size[0],\n",
    "                'Groups': module.groups,\n",
    "                'Params': params\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(conv_stats)\n",
    "    \n",
    "    # 타입별 통계\n",
    "    print(f\"\\n[Conv Type Distribution]\")\n",
    "    type_dist = df.groupby('Type').agg({'Params': ['count', 'sum']})\n",
    "    type_dist.columns = ['Count', 'Total Params']\n",
    "    type_dist['Avg Params'] = type_dist['Total Params'] / type_dist['Count']\n",
    "    print(type_dist.to_string())\n",
    "    \n",
    "    # 커널 크기별 통계\n",
    "    print(f\"\\n[Kernel Size Distribution]\")\n",
    "    kernel_dist = df.groupby('Kernel').agg({'Params': ['count', 'sum']})\n",
    "    kernel_dist.columns = ['Count', 'Total Params']\n",
    "    print(kernel_dist.to_string())\n",
    "    \n",
    "    return df\n",
    "\n",
    "conv1 = analyze_conv_layers(model1, 'JeongWonNet')\n",
    "conv2 = analyze_conv_layers(model2, 'CMUNeXt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 채널 수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_config(model, name):\n",
    "    \"\"\"모델의 채널 구성 추출\"\"\"\n",
    "    channels = []\n",
    "    \n",
    "    for n, m in model.named_modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            if m.in_channels not in channels:\n",
    "                channels.append(m.in_channels)\n",
    "            if m.out_channels not in channels:\n",
    "                channels.append(m.out_channels)\n",
    "    \n",
    "    channels = sorted(set(channels))\n",
    "    return channels\n",
    "\n",
    "ch1 = get_channel_config(model1, 'JeongWonNet')\n",
    "ch2 = get_channel_config(model2, 'CMUNeXt')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Channel Configuration\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nJeongWonNet channels: {ch1}\")\n",
    "print(f\"Max channel: {max(ch1)}\")\n",
    "print(f\"\\nCMUNeXt channels: {ch2}\")\n",
    "print(f\"Max channel: {max(ch2)}\")\n",
    "print(f\"\\nMax channel ratio: {max(ch2)/max(ch1):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Encoder/Decoder 구조 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_encoder_decoder(model, name):\n",
    "    \"\"\"Encoder/Decoder 파라미터 분포\"\"\"\n",
    "    encoder_params = 0\n",
    "    decoder_params = 0\n",
    "    other_params = 0\n",
    "    \n",
    "    for n, p in model.named_parameters():\n",
    "        params = p.numel()\n",
    "        if 'encoder' in n.lower():\n",
    "            encoder_params += params\n",
    "        elif 'decoder' in n.lower():\n",
    "            decoder_params += params\n",
    "        else:\n",
    "            other_params += params\n",
    "    \n",
    "    total = encoder_params + decoder_params + other_params\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Encoder: {encoder_params:>10,} ({encoder_params/total*100:>5.1f}%)\")\n",
    "    print(f\"  Decoder: {decoder_params:>10,} ({decoder_params/total*100:>5.1f}%)\")\n",
    "    print(f\"  Other:   {other_params:>10,} ({other_params/total*100:>5.1f}%)\")\n",
    "    print(f\"  Total:   {total:>10,}\")\n",
    "    \n",
    "    return {'encoder': encoder_params, 'decoder': decoder_params, 'other': other_params}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Encoder/Decoder Distribution\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ed1 = analyze_encoder_decoder(model1, 'JeongWonNet')\n",
    "ed2 = analyze_encoder_decoder(model2, 'CMUNeXt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 복잡도 효율성 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 측정 결과 (measure_efficiency.ipynb에서)\n",
    "measured = {\n",
    "    'JeongWonNet': {'params': 9650, 'flops': 11.55e6, 'gpu_ms': 0.700, 'cpu_ms': 2.033},\n",
    "    'CMUNeXt': {'params': 144980, 'flops': 776.55e6, 'gpu_ms': 1.454, 'cpu_ms': 8.025}\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Efficiency Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "j = measured['JeongWonNet']\n",
    "c = measured['CMUNeXt']\n",
    "\n",
    "print(f\"\\n{'Metric':<25} {'JeongWonNet':>12} {'CMUNeXt':>12} {'Reduction':>12}\")\n",
    "print(\"-\"*65)\n",
    "print(f\"{'Parameters':<25} {j['params']:>12,} {c['params']:>12,} {c['params']/j['params']:>11.1f}x\")\n",
    "print(f\"{'FLOPs':<25} {j['flops']/1e6:>11.2f}M {c['flops']/1e6:>11.2f}M {c['flops']/j['flops']:>11.1f}x\")\n",
    "print(f\"{'GPU Latency (ms)':<25} {j['gpu_ms']:>12.3f} {c['gpu_ms']:>12.3f} {c['gpu_ms']/j['gpu_ms']:>11.1f}x\")\n",
    "print(f\"{'CPU Latency (ms)':<25} {j['cpu_ms']:>12.3f} {c['cpu_ms']:>12.3f} {c['cpu_ms']/j['cpu_ms']:>11.1f}x\")\n",
    "print(f\"{'FLOPs/Param':<25} {j['flops']/j['params']:>12.1f} {c['flops']/c['params']:>12.1f} {(c['flops']/c['params'])/(j['flops']/j['params']):>11.1f}x\")\n",
    "print(f\"{'Throughput (GPU FPS)':<25} {1000/j['gpu_ms']:>12.1f} {1000/c['gpu_ms']:>12.1f} {(1000/j['gpu_ms'])/(1000/c['gpu_ms']):>11.1f}x\")\n",
    "print(f\"{'Throughput (CPU FPS)':<25} {1000/j['cpu_ms']:>12.1f} {1000/c['cpu_ms']:>12.1f} {(1000/j['cpu_ms'])/(1000/c['cpu_ms']):>11.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "models = ['JeongWonNet', 'CMUNeXt']\n",
    "colors = ['#2ecc71', '#3498db']\n",
    "\n",
    "# 1. Parameters\n",
    "ax1 = axes[0, 0]\n",
    "params = [j['params'], c['params']]\n",
    "bars = ax1.bar(models, params, color=colors)\n",
    "ax1.set_ylabel('Parameters')\n",
    "ax1.set_title('Parameters Comparison')\n",
    "for bar, val in zip(bars, params):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{val:,}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 2. FLOPs\n",
    "ax2 = axes[0, 1]\n",
    "flops = [j['flops']/1e6, c['flops']/1e6]\n",
    "bars = ax2.bar(models, flops, color=colors)\n",
    "ax2.set_ylabel('FLOPs (M)')\n",
    "ax2.set_title('FLOPs Comparison')\n",
    "for bar, val in zip(bars, flops):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{val:.1f}M', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 3. Latency\n",
    "ax3 = axes[1, 0]\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "gpu = [j['gpu_ms'], c['gpu_ms']]\n",
    "cpu = [j['cpu_ms'], c['cpu_ms']]\n",
    "bars1 = ax3.bar(x - width/2, gpu, width, label='GPU', color='#e74c3c')\n",
    "bars2 = ax3.bar(x + width/2, cpu, width, label='CPU', color='#9b59b6')\n",
    "ax3.set_ylabel('Latency (ms)')\n",
    "ax3.set_title('Inference Latency')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(models)\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Reduction Ratio\n",
    "ax4 = axes[1, 1]\n",
    "metrics = ['Params', 'FLOPs', 'GPU', 'CPU']\n",
    "ratios = [c['params']/j['params'], c['flops']/j['flops'], \n",
    "          c['gpu_ms']/j['gpu_ms'], c['cpu_ms']/j['cpu_ms']]\n",
    "bars = ax4.barh(metrics, ratios, color='#f39c12')\n",
    "ax4.set_xlabel('CMUNeXt / JeongWonNet Ratio')\n",
    "ax4.set_title('Complexity Ratio (CMUNeXt vs JeongWonNet)')\n",
    "ax4.axvline(x=1, color='gray', linestyle='--', alpha=0.5)\n",
    "for bar, val in zip(bars, ratios):\n",
    "    ax4.text(bar.get_width(), bar.get_y() + bar.get_height()/2, f'{val:.1f}x', \n",
    "             ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('complexity_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nSaved: complexity_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "JeongWonNet vs CMUNeXt 복잡도 비교:\n",
    "\n",
    "1. Parameters: JeongWonNet이 {c['params']/j['params']:.1f}x 더 작음\n",
    "   - JeongWonNet: {j['params']:,} params\n",
    "   - CMUNeXt: {c['params']:,} params\n",
    "\n",
    "2. FLOPs: JeongWonNet이 {c['flops']/j['flops']:.1f}x 더 적은 연산\n",
    "   - JeongWonNet: {j['flops']/1e6:.2f}M FLOPs\n",
    "   - CMUNeXt: {c['flops']/1e6:.2f}M FLOPs\n",
    "\n",
    "3. GPU Latency: JeongWonNet이 {c['gpu_ms']/j['gpu_ms']:.1f}x 더 빠름\n",
    "   - JeongWonNet: {j['gpu_ms']:.3f} ms\n",
    "   - CMUNeXt: {c['gpu_ms']:.3f} ms\n",
    "\n",
    "4. CPU Latency: JeongWonNet이 {c['cpu_ms']/j['cpu_ms']:.1f}x 더 빠름\n",
    "   - JeongWonNet: {j['cpu_ms']:.3f} ms\n",
    "   - CMUNeXt: {c['cpu_ms']:.3f} ms\n",
    "\n",
    "핵심 차이점:\n",
    "- JeongWonNet: Depthwise Separable Conv + 작은 채널 수\n",
    "- CMUNeXt: 더 큰 채널 수와 복잡한 구조\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
